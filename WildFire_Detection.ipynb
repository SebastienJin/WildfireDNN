{
  "cells": [
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-14T10:05:24.897529Z",
          "start_time": "2025-01-14T10:05:21.958044Z"
        },
        "id": "4fee379d29fd072f"
      },
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torchvision.models import (\n",
        "    # ======================= ResNet ======================= #\n",
        "    resnet18, ResNet18_Weights,\n",
        "    resnet34, ResNet34_Weights,\n",
        "    resnet50, ResNet50_Weights,\n",
        "    resnet101, ResNet101_Weights,\n",
        "    resnet152, ResNet152_Weights,\n",
        "    # ===================== Mobile Net ===================== #\n",
        "    mobilenet_v3_small, MobileNet_V3_Small_Weights,\n",
        "    mobilenet_v3_large, MobileNet_V3_Large_Weights,\n",
        "    # ==================== EfficientNet ==================== #\n",
        "    efficientnet_b0, EfficientNet_B0_Weights,\n",
        "    efficientnet_b1, EfficientNet_B1_Weights,\n",
        "    efficientnet_v2_s, EfficientNet_V2_S_Weights,\n",
        "    efficientnet_v2_m, EfficientNet_V2_M_Weights,\n",
        "    efficientnet_v2_l, EfficientNet_V2_L_Weights,\n",
        "    # ================= Vision Transformer ================= #\n",
        "    vit_b_16, ViT_B_16_Weights,\n",
        "    vit_b_32, ViT_B_32_Weights,\n",
        "    vit_l_16, ViT_L_16_Weights,\n",
        "    vit_l_32, ViT_L_32_Weights,\n",
        ")\n",
        "\n",
        "from data_loader import get_wildfire_datasets"
      ],
      "id": "4fee379d29fd072f",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Since the model weights of the Vit series require a lot of space, it is recommended to use them separately from other models.**"
      ],
      "metadata": {
        "id": "p_K5LcAYuABe"
      },
      "id": "p_K5LcAYuABe"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-14T10:06:05.839529Z",
          "start_time": "2025-01-14T10:05:58.269340Z"
        },
        "id": "c9234667c68f5882"
      },
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "BATCHSIZE = 64\n",
        "\n",
        "# logging setup\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
        "\n",
        "# Define models for feature extraction\n",
        "MODELS = {\n",
        "    # name: [model, param_size]\n",
        "    # =============================================================== ResNet =============================================================== #\n",
        "    \"resnet18\": [resnet18(weights=ResNet18_Weights.DEFAULT), sum(p.numel() for p in resnet18(weights=ResNet18_Weights.DEFAULT).parameters())],\n",
        "    \"resnet34\": [resnet34(weights=ResNet34_Weights.DEFAULT), sum(p.numel() for p in resnet34(weights=ResNet34_Weights.DEFAULT).parameters())],\n",
        "    \"resnet50\": [resnet50(weights=ResNet50_Weights.DEFAULT), sum(p.numel() for p in resnet50(weights=ResNet50_Weights.DEFAULT).parameters())],\n",
        "    \"resnet101\": [resnet101(weights=ResNet101_Weights.DEFAULT), sum(p.numel() for p in resnet101(weights=ResNet101_Weights.DEFAULT).parameters())],\n",
        "    \"resnet152\": [resnet152(weights=ResNet152_Weights.DEFAULT), sum(p.numel() for p in resnet152(weights=ResNet152_Weights.DEFAULT).parameters())],\n",
        "    # ============================================================= Mobile Net ============================================================= #\n",
        "    \"mobilenetv3small\": [mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.DEFAULT), sum(p.numel() for p in mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.DEFAULT).parameters())],\n",
        "    \"mobilenetv3large\": [mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.DEFAULT), sum(p.numel() for p in mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.DEFAULT).parameters())],\n",
        "    # ============================================================ EfficientNet ============================================================ #\n",
        "    \"efficientnet_b0\": [efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT), sum(p.numel() for p in efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT).parameters())],\n",
        "    \"efficientnet_b1\": [efficientnet_b1(weights=EfficientNet_B1_Weights.DEFAULT), sum(p.numel() for p in efficientnet_b1(weights=EfficientNet_B1_Weights.DEFAULT).parameters())],\n",
        "    \"efficientnet_v2_s\": [efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT), sum(p.numel() for p in efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT).parameters())],\n",
        "    \"efficientnet_v2_m\": [efficientnet_v2_m(weights=EfficientNet_V2_M_Weights.DEFAULT), sum(p.numel() for p in efficientnet_v2_m(weights=EfficientNet_V2_M_Weights.DEFAULT).parameters())],\n",
        "    \"efficientnet_v2_l\": [efficientnet_v2_l(weights=EfficientNet_V2_L_Weights.DEFAULT), sum(p.numel() for p in efficientnet_v2_l(weights=EfficientNet_V2_L_Weights.DEFAULT).parameters())],\n",
        "    # ========================================================= Vision Transformer ========================================================= #\n",
        "    \"vit_b_16\": [vit_b_16(weights=ViT_B_16_Weights.DEFAULT), sum(p.numel() for p in vit_b_16(weights=ViT_B_16_Weights.DEFAULT).parameters())],\n",
        "    \"vit_b_32\": [vit_b_32(weights=ViT_B_32_Weights.DEFAULT), sum(p.numel() for p in vit_b_32(weights=ViT_B_32_Weights.DEFAULT).parameters())],\n",
        "    \"vit_l_16\": [vit_l_16(weights=ViT_L_16_Weights.DEFAULT), sum(p.numel() for p in vit_l_16(weights=ViT_L_16_Weights.DEFAULT).parameters())],\n",
        "    \"vit_l_32\": [vit_l_32(weights=ViT_L_32_Weights.DEFAULT), sum(p.numel() for p in vit_l_32(weights=ViT_L_32_Weights.DEFAULT).parameters())],\n",
        "}\n",
        "\n",
        "# Clear cuda mem and cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "id": "c9234667c68f5882",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-13T16:58:11.863221Z",
          "start_time": "2025-01-13T16:58:11.859610Z"
        },
        "id": "308e0f638e764c73"
      },
      "cell_type": "code",
      "source": [
        "# Extract features function\n",
        "def extract_features(model, dataloader, device):\n",
        "    model.eval()\n",
        "    features = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Extracting features\"):\n",
        "            images, _ = batch\n",
        "            images = images.to(device)\n",
        "            # with torch.autocast(\"cuda\", dtype=torch.float16, enabled=True, cache_enabled=True):\n",
        "            #     feats = model(images).cpu()  # Move features to CPU immediately\n",
        "            feats = model(images).cpu()\n",
        "            features.append(feats)\n",
        "    return torch.cat(features)\n",
        "\n",
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self, input_dim=1000, hidden_dim1=512, hidden_dim2=256):\n",
        "        super(BinaryClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
        "        self.fc3 = nn.Linear(hidden_dim2, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs, num_samples, name):\n",
        "    model.train()\n",
        "    print(\"Training begins!\")\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_features, batch_labels in train_loader:\n",
        "            outputs = model(batch_features)\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * batch_features.size(0)\n",
        "        epoch_loss = running_loss / num_samples\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
        "    torch.save(model.state_dict(), f\"binary_classifier_{name}.pth\")\n",
        "    print(\"Model has been saved.\")\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(predict_model, model, loader, device, true_labels):\n",
        "    features = extract_features(model, loader, device)\n",
        "    test_features = features.to(device)\n",
        "    predicted_labels = torch.round(predict_model(test_features)).int().cpu()\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    report = classification_report(true_labels, predicted_labels, target_names=[\"No Wildfire\", \"Wildfire\"])\n",
        "    cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "    return accuracy, report, cm"
      ],
      "id": "308e0f638e764c73",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-13T16:23:40.955794Z",
          "start_time": "2025-01-13T16:23:29.760353Z"
        },
        "id": "dfa81d6d1e22b50a"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "from torch.utils.data import random_split\n",
        "BATCHSIZE = 64\n",
        "# Load datasets\n",
        "train_ds, test_ds, valid_ds = get_wildfire_datasets()\n",
        "\n",
        "# train\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCHSIZE, shuffle=True)\n",
        "\n",
        "# valid --> new train & new valid\n",
        "val_size = len(valid_ds)\n",
        "\n",
        "train_size = int(val_size * 0.8)\n",
        "valid_size = val_size - train_size\n",
        "\n",
        "new_train_ds, new_valid_ds = random_split(valid_ds, [train_size, valid_size])\n",
        "\n",
        "new_train_loader = DataLoader(new_train_ds, batch_size=BATCHSIZE, shuffle=False)\n",
        "new_train_labels = np.array([label for _, label in tqdm(new_train_ds, desc=\"Extracting new train labels\")])\n",
        "new_train_labels_tensor = torch.tensor(new_train_labels).unsqueeze(-1).float()\n",
        "\n",
        "new_valid_loader = DataLoader(new_valid_ds, batch_size=BATCHSIZE, shuffle=False)\n",
        "new_valid_labels = np.array([label for _, label in tqdm(new_valid_ds, desc=\"Extracting new valid labels\")])\n",
        "new_valid_labels_tensor = torch.tensor(new_valid_labels).unsqueeze(-1).float()\n",
        "\n",
        "# test\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCHSIZE, shuffle=False)\n",
        "test_labels = np.array([label for _, label in tqdm(test_ds, desc=\"Extracting test labels\")])\n",
        "test_labels_tensor = torch.tensor(test_labels).unsqueeze(-1).float()"
      ],
      "id": "dfa81d6d1e22b50a"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-13T16:58:16.086300Z",
          "start_time": "2025-01-13T16:58:16.081854Z"
        },
        "id": "d4bca37ca61ef0bc"
      },
      "cell_type": "code",
      "source": [
        "# estimate the cuda memory usage by batch size and model sizes and image size\n",
        "for model_name, model_ls in MODELS.items():\n",
        "    model = model_ls[0]\n",
        "    cuda_available_memory = torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_reserved(0)\n",
        "    estimated_memory = sum(p.numel() for p in model.parameters()) * 4 / 1024 ** 2  # in MB\n",
        "    logging.info(f\"Estimated model memory: {estimated_memory:.2f} MB\")\n",
        "    if estimated_memory > cuda_available_memory:\n",
        "        raise MemoryError(\"Not enough GPU memory for this model.\")"
      ],
      "id": "d4bca37ca61ef0bc",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-13T16:59:49.827631Z",
          "start_time": "2025-01-13T16:58:17.515373Z"
        },
        "id": "706043f28eb23a54"
      },
      "cell_type": "code",
      "source": [
        "# Prepare models and extract features\n",
        "model_results = {}\n",
        "for model_name, model_ls in tqdm(MODELS.items(), desc=\"Processing models\"):\n",
        "    model = model_ls[0]\n",
        "    logging.info(f\"Setting up {model_name}...\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Extract features\n",
        "    logging.info(f\"Extracting features with {model_name}...\")\n",
        "    valid_loader = new_valid_loader\n",
        "    features = extract_features(model, valid_loader, device)\n",
        "\n",
        "    valid_features = features.to(device)\n",
        "    valid_labels_tensor = new_train_labels_tensor\n",
        "    valid_labels_tensor = valid_labels_tensor.to(device)\n",
        "\n",
        "    mlp_dataset = TensorDataset(valid_features, valid_labels_tensor)\n",
        "    mlp_batch_size = 32\n",
        "    mlp_dataloader = DataLoader(mlp_dataset, batch_size=mlp_batch_size, shuffle=True)\n",
        "\n",
        "    predict_model = BinaryClassifier(input_dim=features.shape[1]).to(device)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(predict_model.parameters(), lr=0.001)\n",
        "\n",
        "    train_model(predict_model, mlp_dataloader, criterion, optimizer, num_epochs=50, num_samples=len(mlp_dataset), name=model_name)\n",
        "\n",
        "    model_results[model_name] = {\n",
        "        \"model\": model,\n",
        "        \"predict_model\": predict_model\n",
        "    }\n",
        "\n",
        "    # Clear cuda memory\n",
        "    model = model.to(torch.device(\"cpu\"))\n",
        "    torch.cuda.empty_cache()"
      ],
      "id": "706043f28eb23a54",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-13T17:00:08.940558Z",
          "start_time": "2025-01-13T16:59:49.849029Z"
        },
        "id": "a33d32756cd4c7ba"
      },
      "cell_type": "code",
      "source": [
        "# Evaluate all models\n",
        "for model_name, data in model_results.items():\n",
        "    logging.info(f\"Evaluating {model_name}...\")\n",
        "\n",
        "    predict_model = data[\"predict_model\"]\n",
        "    model = data[\"model\"]\n",
        "    model = model.to(device)\n",
        "\n",
        "    accuracy, report, cm = evaluate_model(predict_model, model, test_loader, device, test_labels)\n",
        "\n",
        "    print(f\"{model_name} {accuracy * 100:.2f}%\")\n",
        "    # resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "    print(f\"{MODELS[model_name][0]}\")\n",
        "    print(predict_model)\n",
        "    print(f\"{model_name} classification report:\\n{report}\")\n",
        "\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f\"{model_name} Confusion Matrix\")\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "id": "a33d32756cd4c7ba",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results Records"
      ],
      "metadata": {
        "id": "xVSefQ8qxGAs"
      },
      "id": "xVSefQ8qxGAs"
    },
    {
      "metadata": {
        "id": "b66178b61953cd3a"
      },
      "cell_type": "markdown",
      "source": [
        "### ResNet\n",
        "```txt\n",
        "resnet18 95.97%\n",
        "resnet18 classification report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " No Wildfire       0.96      0.95      0.95      2820\n",
        "    Wildfire       0.96      0.97      0.96      3480\n",
        "\n",
        "    accuracy                           0.96      6300\n",
        "   macro avg       0.96      0.96      0.96      6300\n",
        "weighted avg       0.96      0.96      0.96      6300\n",
        "```\n",
        "```txt\n",
        "resnet34 95.86%\n",
        "resnet34 classification report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " No Wildfire       0.95      0.96      0.95      2820\n",
        "    Wildfire       0.97      0.96      0.96      3480\n",
        "\n",
        "    accuracy                           0.96      6300\n",
        "   macro avg       0.96      0.96      0.96      6300\n",
        "weighted avg       0.96      0.96      0.96      6300\n",
        "```\n",
        "```txt\n",
        "resnet50 97.22%\n",
        "resnet50 classification report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " No Wildfire       0.97      0.97      0.97      2820\n",
        "    Wildfire       0.98      0.97      0.97      3480\n",
        "\n",
        "    accuracy                           0.97      6300\n",
        "   macro avg       0.97      0.97      0.97      6300\n",
        "weighted avg       0.97      0.97      0.97      6300\n",
        "```\n",
        "```txt\n",
        "resnet101 97.27%\n",
        "resnet101 classification report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " No Wildfire       0.98      0.96      0.97      2820\n",
        "    Wildfire       0.97      0.98      0.98      3480\n",
        "\n",
        "    accuracy                           0.97      6300\n",
        "   macro avg       0.97      0.97      0.97      6300\n",
        "weighted avg       0.97      0.97      0.97      6300\n",
        "```\n",
        "```txt\n",
        "resnet152 97.06%\n",
        "resnet152 classification report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " No Wildfire       0.97      0.96      0.97      2820\n",
        "    Wildfire       0.97      0.98      0.97      3480\n",
        "\n",
        "    accuracy                           0.97      6300\n",
        "   macro avg       0.97      0.97      0.97      6300\n",
        "weighted avg       0.97      0.97      0.97      6300\n",
        "```\n",
        "\n",
        "### MobileNetv3\n",
        "```txt\n",
        "mobilenetv3small 97.02%\n",
        "mobilenetv3small classification report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " No Wildfire       0.97      0.97      0.97      2820\n",
        "    Wildfire       0.97      0.97      0.97      3480\n",
        "\n",
        "    accuracy                           0.97      6300\n",
        "   macro avg       0.97      0.97      0.97      6300\n",
        "weighted avg       0.97      0.97      0.97      6300\n",
        "```\n",
        "```txt\n",
        "mobilenetv3large 97.30%\n",
        "mobilenetv3large classification report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " No Wildfire       0.97      0.97      0.97      2820\n",
        "    Wildfire       0.97      0.98      0.98      3480\n",
        "\n",
        "    accuracy                           0.97      6300\n",
        "   macro avg       0.97      0.97      0.97      6300\n",
        "weighted avg       0.97      0.97      0.97      6300\n",
        "```\n",
        "### EfficientNet\n",
        "```txt\n",
        "efficientnet_b0 96.73%\n",
        "efficientnet_b0 classification report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " No Wildfire       0.97      0.96      0.96      2820\n",
        "    Wildfire       0.97      0.97      0.97      3480\n",
        "\n",
        "    accuracy                           0.97      6300\n",
        "   macro avg       0.97      0.97      0.97      6300\n",
        "weighted avg       0.97      0.97      0.97      6300\n",
        "```\n",
        "```txt\n",
        "efficientnet_b1 97.56%\n",
        "efficientnet_b1 classification report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " No Wildfire       0.98      0.97      0.97      2820\n",
        "    Wildfire       0.97      0.98      0.98      3480\n",
        "\n",
        "    accuracy                           0.98      6300\n",
        "   macro avg       0.98      0.97      0.98      6300\n",
        "weighted avg       0.98      0.98      0.98      6300\n",
        "```\n",
        "```txt\n",
        "efficientnet_v2_s 96.43%\n",
        "efficientnet_v2_s classification report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " No Wildfire       0.96      0.96      0.96      2820\n",
        "    Wildfire       0.97      0.97      0.97      3480\n",
        "\n",
        "    accuracy                           0.96      6300\n",
        "   macro avg       0.96      0.96      0.96      6300\n",
        "weighted avg       0.96      0.96      0.96      6300\n",
        "```\n",
        "```txt\n",
        "efficientnet_v2_m 95.29%\n",
        "efficientnet_v2_m classification report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " No Wildfire       0.95      0.95      0.95      2820\n",
        "    Wildfire       0.96      0.96      0.96      3480\n",
        "\n",
        "    accuracy                           0.95      6300\n",
        "   macro avg       0.95      0.95      0.95      6300\n",
        "weighted avg       0.95      0.95      0.95      6300\n",
        "```\n",
        "```txt\n",
        "efficientnet_v2_l 97.27%\n",
        "efficientnet_v2_l classification report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " No Wildfire       0.97      0.97      0.97      2820\n",
        "    Wildfire       0.98      0.97      0.98      3480\n",
        "\n",
        "    accuracy                           0.97      6300\n",
        "   macro avg       0.97      0.97      0.97      6300\n",
        "weighted avg       0.97      0.97      0.97      6300\n",
        "```\n",
        "### ViT\n",
        "```txt\n",
        "vit_b_16 97.05%\n",
        "vit_b_16 classification report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " No Wildfire       0.97      0.96      0.97      2820\n",
        "    Wildfire       0.97      0.98      0.97      3480\n",
        "\n",
        "    accuracy                           0.97      6300\n",
        "   macro avg       0.97      0.97      0.97      6300\n",
        "weighted avg       0.97      0.97      0.97      6300\n",
        "```\n",
        "```txt\n",
        "vit_b_32 96.98%\n",
        "vit_b_32 classification report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " No Wildfire       0.97      0.96      0.97      2820\n",
        "    Wildfire       0.97      0.98      0.97      3480\n",
        "\n",
        "    accuracy                           0.97      6300\n",
        "   macro avg       0.97      0.97      0.97      6300\n",
        "weighted avg       0.97      0.97      0.97      6300\n",
        "```\n",
        "```txt\n",
        "vit_l_16 97.75%\n",
        "vit_l_16 classification report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " No Wildfire       0.98      0.97      0.97      2820\n",
        "    Wildfire       0.98      0.98      0.98      3480\n",
        "\n",
        "    accuracy                           0.98      6300\n",
        "   macro avg       0.98      0.98      0.98      6300\n",
        "weighted avg       0.98      0.98      0.98      6300\n",
        "```\n",
        "```txt\n",
        "vit_l_32 96.78%\n",
        "vit_l_32 classification report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " No Wildfire       0.97      0.96      0.96      2820\n",
        "    Wildfire       0.97      0.97      0.97      3480\n",
        "\n",
        "    accuracy                           0.97      6300\n",
        "   macro avg       0.97      0.97      0.97      6300\n",
        "weighted avg       0.97      0.97      0.97      6300\n",
        "```\n",
        "```"
      ],
      "id": "b66178b61953cd3a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### If you want to test the models from the pretrained classifier weights:"
      ],
      "metadata": {
        "id": "fHClvg4oUFOC"
      },
      "id": "fHClvg4oUFOC"
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, model_ls in tqdm(MODELS.items(), desc=\"Testing models\"):\n",
        "\n",
        "    model = model_ls[0]\n",
        "    logging.info(f\"Evaluating {model_name}...\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    output_dim = 1000\n",
        "    predict_model = BinaryClassifier(input_dim=output_dim).to(device)\n",
        "    state_dict = torch.load(f\"./models/binary_classifier_{model_name}.pth\", weights_only=True, map_location=device)\n",
        "    predict_model.load_state_dict(state_dict)\n",
        "    predict_model.eval()\n",
        "\n",
        "    accuracy, report, cm = evaluate_model(predict_model, model, test_loader, device, test_labels)\n",
        "\n",
        "    print(f\"{model_name} {accuracy * 100:.2f}%\")\n",
        "    print(f\"{MODELS[model_name][0]}\")\n",
        "    print(predict_model)\n",
        "    print(f\"{model_name} classification report:\\n{report}\")\n",
        "\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f\"{model_name} Confusion Matrix\")\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "JGABJwrq_HPE"
      },
      "id": "JGABJwrq_HPE",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}